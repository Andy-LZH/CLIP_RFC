
  7%|██████████▏                                                                                                                               | 5/68 [00:01<00:15,  4.17it/s]
loss:  tensor(0.7273, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.7868, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.3375, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9047, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.3834, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9474, device='cuda:0', grad_fn=<NllLossBackward0>)

 21%|████████████████████████████▏                                                                                                            | 14/68 [00:03<00:11,  4.51it/s]
loss:  tensor(0.5911, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4406, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0736, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9301, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.6645, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.6177, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.5388, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4367, device='cuda:0', grad_fn=<NllLossBackward0>)

 34%|██████████████████████████████████████████████▎                                                                                          | 23/68 [00:05<00:10,  4.31it/s]
loss:  tensor(0.6909, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.5164, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.5246, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.5560, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.5160, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4534, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4547, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4724, device='cuda:0', grad_fn=<NllLossBackward0>)

 47%|████████████████████████████████████████████████████████████████▍                                                                        | 32/68 [00:07<00:07,  4.54it/s]
loss:  tensor(0.4073, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4922, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4710, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.6483, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.7065, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4480, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.5006, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.3962, device='cuda:0', grad_fn=<NllLossBackward0>)

 60%|██████████████████████████████████████████████████████████████████████████████████▌                                                      | 41/68 [00:09<00:06,  4.30it/s]
loss:  tensor(0.3620, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4873, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4806, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4348, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8559, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.3611, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.3871, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.5344, device='cuda:0', grad_fn=<NllLossBackward0>)

 74%|████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 50/68 [00:11<00:04,  4.19it/s]
loss:  tensor(0.3711, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.5699, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.6114, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.6748, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4923, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4717, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.5358, device='cuda:0', grad_fn=<NllLossBackward0>)

 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                    | 58/68 [00:13<00:02,  4.07it/s]
loss:  tensor(0.4426, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4642, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.5380, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4359, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4196, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4317, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.3312, device='cuda:0', grad_fn=<NllLossBackward0>)

 99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 67/68 [00:15<00:00,  4.32it/s]
loss:  tensor(0.7374, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4912, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4310, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.6805, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4387, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.3865, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.3410, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4669, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.4345, device='cuda:0', grad_fn=<NllLossBackward0>)
Training loss: 0.017940498672682662, accuracy: 0.7245977011494252
tensor([[0.8048, 0.1952]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
label:  [0]
[[0.8047569]]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:15<00:00,  4.31it/s]
  0%|▏                                                                                                                                        | 1/977 [00:01<16:35,  1.02s/it]
tensor([[0.1598, 0.8402]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
label:  [0]
[[0.15984339]]
[array([0.8047569], dtype=float32), array([0.15984339], dtype=float32)]
tensor([[0.6914, 0.3086]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
label:  [1]
[[0.308627]]

  0%|▍                                                                                                                                        | 3/977 [00:03<16:33,  1.02s/it]
tensor([[0.2241, 0.7759]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
label:  [0]
[[0.22409964]]
[array([0.8047569], dtype=float32), array([0.15984339], dtype=float32), array([0.308627], dtype=float32), array([0.22409964], dtype=float32)]
tensor([[0.5962, 0.4038]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
label:  [0]
[[0.596196]]

  1%|▋                                                                                                                                        | 5/977 [00:05<16:31,  1.02s/it]
tensor([[0.7326, 0.2674]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
label:  [0]
[[0.73260593]]

  1%|▉                                                                                                                                        | 7/977 [00:07<16:28,  1.02s/it]
tensor([[0.9468, 0.0532]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
label:  [0]
[[0.9467938]]
[array([0.8047569], dtype=float32), array([0.15984339], dtype=float32), array([0.308627], dtype=float32), array([0.22409964], dtype=float32), array([0.596196], dtype=float32), array([0.73260593], dtype=float32), array([0.9467938], dtype=float32)]
tensor([[0.0633, 0.9367]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
label:  [0]
[[0.06333873]]

  1%|█▎                                                                                                                                       | 9/977 [00:09<16:27,  1.02s/it]
tensor([[0.4662, 0.5338]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
label:  [0]
[[0.46624345]]
[array([0.8047569], dtype=float32), array([0.15984339], dtype=float32), array([0.308627], dtype=float32), array([0.22409964], dtype=float32), array([0.596196], dtype=float32), array([0.73260593], dtype=float32), array([0.9467938], dtype=float32), array([0.06333873], dtype=float32), array([0.46624345], dtype=float32)]
tensor([[0.5739, 0.4261]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
label:  [0]
[[0.57393014]]

  1%|█▌                                                                                                                                      | 11/977 [00:11<16:25,  1.02s/it]
tensor([[0.2275, 0.7725]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
label:  [0]
[[0.22754066]]
[array([0.8047569], dtype=float32), array([0.15984339], dtype=float32), array([0.308627], dtype=float32), array([0.22409964], dtype=float32), array([0.596196], dtype=float32), array([0.73260593], dtype=float32), array([0.9467938], dtype=float32), array([0.06333873], dtype=float32), array([0.46624345], dtype=float32), array([0.57393014], dtype=float32), array([0.22754066], dtype=float32)]
tensor([[0.6252, 0.3748]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
label:  [0]
[[0.6252048]]
  1%|█▋                                                                                                                                      | 12/977 [00:12<16:43,  1.04s/it]
Traceback (most recent call last):
  File "train_MHIST.py", line 223, in <module>
    train(train_data, test_data, model_backbone, max_epoch)
  File "train_MHIST.py", line 192, in train
    time.sleep(1)
KeyboardInterrupt
tensor([[0.9810, 0.0190]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
label:  [0]
[[0.98102677]]
[array([0.8047569], dtype=float32), array([0.15984339], dtype=float32), array([0.308627], dtype=float32), array([0.22409964], dtype=float32), array([0.596196], dtype=float32), array([0.73260593], dtype=float32), array([0.9467938], dtype=float32), array([0.06333873], dtype=float32), array([0.46624345], dtype=float32), array([0.57393014], dtype=float32), array([0.22754066], dtype=float32), array([0.6252048], dtype=float32), array([0.98102677], dtype=float32)]