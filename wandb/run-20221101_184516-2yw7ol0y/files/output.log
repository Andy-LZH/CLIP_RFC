  0%|                                                                                                                                                  | 0/68 [00:00<?, ?it/s]/opt/anaconda/envs/dassl/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
 13%|██████████████████▎                                                                                                                       | 9/68 [00:01<00:08,  6.75it/s]
loss:  tensor(0.9233, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0443, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8385, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0098, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0106, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0108, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0816, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9799, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0372, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0379, device='cuda:0', grad_fn=<NllLossBackward0>)

 35%|████████████████████████████████████████████████▎                                                                                        | 24/68 [00:03<00:05,  7.45it/s]
loss:  tensor(1.1277, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0239, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0153, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9718, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9134, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.7601, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9845, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9370, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9161, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8925, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0071, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9446, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8833, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0423, device='cuda:0', grad_fn=<NllLossBackward0>)

 57%|██████████████████████████████████████████████████████████████████████████████▌                                                          | 39/68 [00:05<00:03,  7.59it/s]
loss:  tensor(0.9043, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0253, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9108, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8627, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9936, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8402, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0523, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9698, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0694, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9750, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0032, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9453, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0561, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0610, device='cuda:0', grad_fn=<NllLossBackward0>)

 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 54/68 [00:07<00:01,  7.37it/s]
loss:  tensor(1.0262, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8007, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9021, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9760, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.7900, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0287, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8457, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0511, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8244, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0377, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9389, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9740, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9421, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9188, device='cuda:0', grad_fn=<NllLossBackward0>)
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:09<00:00,  7.21it/s]
  1%|██                                                                                                                                        | 1/68 [00:00<00:08,  7.57it/s]
loss:  tensor(0.9461, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9398, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0335, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0378, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9770, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8944, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9511, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9366, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9101, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8825, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0094, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9656, device='cuda:0', grad_fn=<NllLossBackward0>)
Training loss: 0.030135180840547057, accuracy: 0.2896551724137931
loss:  tensor(0.8775, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8928, device='cuda:0', grad_fn=<NllLossBackward0>)

 22%|██████████████████████████████▏                                                                                                          | 15/68 [00:02<00:07,  7.50it/s]
loss:  tensor(0.9503, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0024, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0176, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0922, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0075, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9940, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0058, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0801, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9420, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9810, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9654, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9118, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9506, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9342, device='cuda:0', grad_fn=<NllLossBackward0>)

 44%|████████████████████████████████████████████████████████████▍                                                                            | 30/68 [00:04<00:05,  7.47it/s]
loss:  tensor(1.0382, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0122, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0277, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0155, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9879, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9670, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9419, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0505, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9481, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.1015, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8445, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.7280, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8512, device='cuda:0', grad_fn=<NllLossBackward0>)

 66%|██████████████████████████████████████████████████████████████████████████████████████████▋                                              | 45/68 [00:06<00:03,  7.56it/s]
loss:  tensor(0.9318, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9737, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.7669, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0294, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0710, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9954, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0089, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9700, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9549, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9452, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9564, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0005, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9393, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.1379, device='cuda:0', grad_fn=<NllLossBackward0>)

 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 60/68 [00:08<00:01,  7.31it/s]
loss:  tensor(0.9778, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9628, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0437, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9306, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0693, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8897, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9046, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0001, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8852, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9130, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0174, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9490, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9034, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9828, device='cuda:0', grad_fn=<NllLossBackward0>)
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:09<00:00,  7.37it/s]
 10%|██████████████▏                                                                                                                           | 7/68 [00:00<00:08,  7.39it/s]
loss:  tensor(0.9050, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8674, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9317, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9478, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8551, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9213, device='cuda:0', grad_fn=<NllLossBackward0>)
Training loss: 0.030158110322623416, accuracy: 0.2896551724137931
loss:  tensor(0.9128, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9473, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9544, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9799, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8830, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9687, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9880, device='cuda:0', grad_fn=<NllLossBackward0>)

 32%|████████████████████████████████████████████▎                                                                                            | 22/68 [00:02<00:06,  7.58it/s]
loss:  tensor(0.9075, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8678, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9500, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0212, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9608, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8448, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8935, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9487, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0147, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9214, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0961, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9022, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9251, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9929, device='cuda:0', grad_fn=<NllLossBackward0>)

 53%|████████████████████████████████████████████████████████████████████████▌                                                                | 36/68 [00:04<00:04,  7.17it/s]
loss:  tensor(0.9721, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9177, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9901, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9269, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9228, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9784, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8850, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0025, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0465, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8171, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0178, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9709, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9709, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9058, device='cuda:0', grad_fn=<NllLossBackward0>)

 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                                  | 51/68 [00:06<00:02,  6.75it/s]
loss:  tensor(1.0060, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9408, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9407, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9742, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9835, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8335, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0315, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0190, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9351, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9972, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9840, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0144, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8647, device='cuda:0', grad_fn=<NllLossBackward0>)

 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉      | 65/68 [00:08<00:00,  7.16it/s]
loss:  tensor(0.9716, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0791, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8705, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8450, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0236, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9738, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0732, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9985, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9352, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0761, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0481, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9655, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9726, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0153, device='cuda:0', grad_fn=<NllLossBackward0>)
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:09<00:00,  7.29it/s]
 18%|████████████████████████▏                                                                                                                | 12/68 [00:01<00:07,  7.11it/s]
loss:  tensor(0.9188, device='cuda:0', grad_fn=<NllLossBackward0>)
Training loss: 0.030168846201622624, accuracy: 0.2896551724137931
loss:  tensor(0.8203, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8575, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9353, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0418, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0159, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8948, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9404, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9097, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9292, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0164, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9419, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9162, device='cuda:0', grad_fn=<NllLossBackward0>)

 40%|██████████████████████████████████████████████████████▍                                                                                  | 27/68 [00:03<00:05,  7.23it/s]
loss:  tensor(0.9688, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.1129, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0071, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9009, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0296, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.7755, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0234, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0411, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9547, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9932, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0422, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9150, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0234, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8621, device='cuda:0', grad_fn=<NllLossBackward0>)

 60%|██████████████████████████████████████████████████████████████████████████████████▌                                                      | 41/68 [00:05<00:03,  7.32it/s]
loss:  tensor(1.0119, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9619, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9165, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0296, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0086, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0133, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9005, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0071, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9751, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.1066, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9448, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0016, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9859, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0550, device='cuda:0', grad_fn=<NllLossBackward0>)

 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                      | 57/68 [00:07<00:01,  7.58it/s]
loss:  tensor(0.8805, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8104, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8576, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9315, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0501, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9311, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9956, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9720, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8932, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9803, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0505, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9130, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9671, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9944, device='cuda:0', grad_fn=<NllLossBackward0>)
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:09<00:00,  7.36it/s]
  4%|██████                                                                                                                                    | 3/68 [00:00<00:09,  7.03it/s]
loss:  tensor(0.9171, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0463, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8479, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9167, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9445, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9959, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0879, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9239, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0307, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9893, device='cuda:0', grad_fn=<NllLossBackward0>)
Training loss: 0.03016466096899975, accuracy: 0.2896551724137931
loss:  tensor(1.0426, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0407, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9903, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9453, device='cuda:0', grad_fn=<NllLossBackward0>)

 26%|████████████████████████████████████▎                                                                                                    | 18/68 [00:02<00:06,  7.56it/s]
loss:  tensor(0.9343, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8971, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8743, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9378, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9971, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0882, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.8964, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0533, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9795, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9433, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9798, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9745, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(0.9210, device='cuda:0', grad_fn=<NllLossBackward0>)
 31%|██████████████████████████████████████████▎                                                                                              | 21/68 [00:03<00:06,  6.97it/s]
Traceback (most recent call last):
  File "train_MHIST.py", line 132, in <module>
    model_backbone = torchvision.models.resnet34().to(device)
  File "train_MHIST.py", line 82, in train
    val, index_ = torch.max(y_pred.data, axis=1)
KeyboardInterrupt
loss:  tensor(1.0952, device='cuda:0', grad_fn=<NllLossBackward0>)
loss:  tensor(1.0110, device='cuda:0', grad_fn=<NllLossBackward0>)